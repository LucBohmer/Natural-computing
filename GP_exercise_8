import numpy as np
from gplearn.genetic import SymbolicRegressor
import gplearn
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt

def sae(y,y_pred,w):
    return -np.sum(np.abs(y_pred - y))

loss = gplearn.fitness.make_fitness(sae,greater_is_better=True)

# function nodes
function_set = ['add','sub', 'mul', 'div', 'sin','log','cos']

input = np.arange(-1,1.1,0.1).reshape(-1,1)

output = np.array([0.0000, -0.1629, -0.2624, -0.3129, -0.3264, -0.3125, -0.2784, -0.2289, -0.1664, -0.0909,
 0.0 ,0.1111 ,0.2496 ,0.4251 ,0.6496 ,0.9375 ,1.3056 ,1.7731 ,2.3616 ,3.0951 ,4.0000]).reshape(-1,1)

gp = SymbolicRegressor(1000,p_crossover=0.7,p_point_mutation=0,metric = loss,
                               generations=50, function_set=function_set, const_range=None, verbose=1)

gp.fit(input, output)
print(gp._program)
best_fitnesses = gp.run_details_['best_fitness']
plt.plot(best_fitnesses)
plt.xlabel("Generation")
plt.ylabel("Fitness")
plt.title("A) Fitness of best individual in each generation")
plt.show()

best_lengths = gp.run_details_['best_length']
plt.plot(best_lengths)
plt.xlabel("Generation")
plt.ylabel("Size")
plt.title("B, 1) Number of nodes of the individuals with the highest fitness in their generation")
plt.show()

average_lengths = gp.run_details_['average_length']
plt.plot(average_lengths)
plt.xlabel("Generation")
plt.ylabel("Average Size")
plt.title("B, 2) Average number of nodes for each generation")
plt.show()

print(gp.score(input, output))